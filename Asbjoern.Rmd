---
title: "Optimisation 2.2: Exercises"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Algorithmic differentiation

Work out all the details (with pen and paper) of calculating $\dot{v}_1$ and $\dot{v}_2$ in the forward mode of the example in slides.

Work out all the details (with pen and paper) of calculating $\bar{v}_1$ in the reverse mode of the example in slides.

Complete the algorithmic differentiation implementation for univariate ($\mathbb{R} \to \mathbb{R}$) functions in `R`'s S3 class system (for the often used functions such as `/`, `exp` etc.).

```{r}
create_ADnum <- function(val, deriv = 1) {
  x <- list(val = val, deriv = deriv)
  class(x) <- "ADnum"
  return(x)
}


print.ADnum <- function(x, ...) {
  cat("value = ", x$val,
      " and deriv = ", x$deriv, "\n", sep = "")
  return(invisible(x))
}


Ops.ADnum <- function(e1, e2) {
# LHS constant, e.g. 2*x: e1 is a number 2, convert to ADnum
  if (.Method[1] == "") {
    e1 <- create_ADnum(e1, 0)
  }
# RHS constant, e.g. x*2: e2 is a number 2, convert to ADnum
  if (.Method[2] == "") {
    e2 <- create_ADnum(e2, 0)
  }
  if (.Generic == "*") {
    return(create_ADnum(e1$val * e2$val, e1$deriv*e2$val + e2$deriv*e1$val))
  }
  if (.Generic == "/"){
    return(create_ADnum(e1$val / e2$val, (e2$val * e1$deriv - e1$val * e2$deriv) / ((e2$val)^2) ))
  }
  if (.Generic == "+"){
    return(create_ADnum(e1$val + e2$val, e1$deriv + e2$deriv))
  }
  if (.Generic == "-"){
    return(create_ADnum(e1$val - e2$val, e1$deriv - e2$deriv))
  }
stop("Function ’", .Generic, "’ not yet implemented for ADnum")
}

Math.ADnum <- function(x, ...) {
  if (.Generic == "cos") {
    # Before: create_ADnum(cos(x£val), -sin(x£val))
    return(create_ADnum(cos(x$val), -sin(x$val) * x$deriv))
  } else if (.Generic == "sin") {
    # Before: create_ADnum(sin(x£val), cos(x£val))
    return(create_ADnum(sin(x$val), cos(x$val) * x$deriv))
  }
    if (.Generic == "exp"){
      return(create_ADnum(exp(x$val), exp(x$val) * x$deriv))
    }
    
    stop("Function ’", .Generic, "’ not yet implemented for ADnum")
}
ADf <- function(x) { sin(x)*cos(x) }
ADf(create_ADnum(2))
ADf2 <- function(x) { sin(x)/cos(x) }
ADf2(create_ADnum(2))
ADf3 <- function(x) { cos(sin(x)*cos(x)) / sin(sin(x)*cos(x)) }
ADf3(create_ADnum(2))
ADf4 <- function(x) { exp(cos(x)) }
ADf4(create_ADnum(2))
ADf5 <- function(x) { exp(4*cos(x)/sin(x)) }
ADf5(create_ADnum(2))
```

Apply it on:

* `ADf <- function(x) { sin(x)*cos(x) }`
* `ADf <- function(x) { sin(x)/cos(x) }`
* `ADf <- function(x) { cos(sin(x)*cos(x)) / sin(sin(x)*cos(x)) }` 
* `ADf <- function(x) { exp(cos(x)) }`
* `ADf <- function(x) { exp(4*cos(x)/sin(x)) }`

```{r}
adfn <- function(x){
  (x[[1]]*x[[2]]*sin(x[[3]])+exp(x[[1]]*x[[2]]))/x[[3]]
}


Gradient <- function(x, funk) {
  g <- list() # tom liste til at fylde inputs ind
  for (i in 1:length(x)) {
    g[[i]] <- create_ADnum(x[i]) # laver ADnum klasser af alle x
  }
  n <- length(g) # antal variable
  pp <- c() # tom vektor til gradient
  for (i in 1L:n) {
    inputs <- vector("list", n) # tom vector til at putte vaerdier og ADnum ind
    for (j in 1L:n) {
      if (j == i) {
        inputs[[j]] <- g[[j]] # ADnum
      } else {
        inputs[[j]] <- g[[j]]$val # fastholdt vaerdi
      }
      
    }
    pp[i] <- funk(inputs)$deriv # i'te indgang i gradient
  }
  pp # gradient
}
Gradient(c(1,2,3), adfn)



```

Compare the results with those of finite differencing and symbolic algebra.

```{r}

```

Experiment with the `madness` package (e.g. check your above results).

```{r}
install.packages("madness")
  madness
```

Extend your implementation to handle multivariate functions (vector arguments) with loops.

```{r}
g <- function(x) {
	n <- length(x)
	g_result <- numeric(n)
	# for...
	g_result
}
g(x)
g_exact(x_value)
```

Try your implementation on the function defined in (8.26) in [NW]. Compare the results with those from the `madness` package, finite differencing, and symbolic algebra.

